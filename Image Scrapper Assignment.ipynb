{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "572ffee2-5085-404a-8c29-538e50ae7c4e",
   "metadata": {},
   "source": [
    "Run All The Code In VS Studio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2e2127-ba6f-45f5-a9f3-3e61b920106a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go to this given URL and solve the following questions\n",
    "\n",
    "# URL: https://www.youtube.com/@PW-Foundation/videos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dd2ca4-16a2-4f73-9d53-7a79226d1b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1. Write a python program to extract the video URL of the first five videos \n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.youtube.com/@PW-Foundation/videos'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "video_links = []\n",
    "\n",
    "# Find all the video link elements\n",
    "link_elements = soup.find_all('a', class_='yt-simple-endpoint inline-block style-scope ytd-thumbnail')\n",
    "\n",
    "# Extract the 'href' attribute value from each link element\n",
    "for link in link_elements:\n",
    "    video_links.append(link['href'])\n",
    "\n",
    "print(video_links) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb42cb3-c6a2-41b4-b4ae-2a5a6cb9fa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install chromedriver-autoinstaller\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ce57ff-439c-4f55-9a37-92397120f3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install selenium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4652d7f7-b625-4ba9-8aa6-467369e2f9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Its Unable TO Install SO Run The Code In VS Code........................................\n",
    "\n",
    "\n",
    "from selenium import webdriver\n",
    "import chromedriver_autoinstaller\n",
    "\n",
    "chromedriver_autoinstaller.install()  # Check if the current version of chromedriver exists\n",
    "                                      # and if it doesn't exist, download it automatically,\n",
    "                                      # then add chromedriver to the path\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"http://www.python.org\")\n",
    "assert \"Python\" in driver.title "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73a4fd2-2f14-4faa-8c7a-1276d94ab7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "\n",
    "url = 'https://www.youtube.com/@PW-Foundation/videos'\n",
    "\n",
    "# Use Selenium to load the dynamic content\n",
    "driver = webdriver.Chrome()  # Make sure you have Chrome WebDriver installed and in PATH\n",
    "driver.get(url)\n",
    "time.sleep(5)  # Wait for the page to load dynamically (you can adjust this time if needed)\n",
    "\n",
    "# Now get the page source with the dynamically loaded content\n",
    "page_source = driver.page_source\n",
    "driver.quit()  # Close the browser\n",
    "\n",
    "soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "video_links = []\n",
    "\n",
    "# Find all the video link elements\n",
    "link_elements = soup.find_all('a', class_='yt-simple-endpoint inline-block style-scope ytd-thumbnail')\n",
    "\n",
    "# Extract the 'href' attribute value from the first five link elements\n",
    "for i, link in enumerate(link_elements):\n",
    "    if i >= 5:\n",
    "        break\n",
    "    href = link.get('href', '')\n",
    "    if href.startswith('/watch'):  # Filter out links that are not video URLs\n",
    "        video_links.append('https://www.youtube.com' + href)\n",
    "\n",
    "# Print the video links\n",
    "print(video_links)\n",
    "\n",
    "\n",
    "# Save the video links into a CSV file\n",
    "csv_file = 'video_links.csv'\n",
    "with open(csv_file, 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Video Links'])\n",
    "    writer.writerows([[link] for link in video_links])\n",
    "\n",
    "print(f\"Video links saved to {csv_file}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "194ef934-dada-4262-9dfd-a6adef03e611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://github.com/iPrasanjitRoy/Python-Project/raw/main/01.PNG\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "url = \"https://github.com/iPrasanjitRoy/Python-Project/raw/main/01.PNG\"  # Update the URL to the direct raw image URL\n",
    "display(Image(url=url))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48276668-fc56-48e4-a1fe-ad11347e4513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2. Write a python program to extract the URL of the video thumbnails of the first five videos \n",
    "\n",
    "\n",
    "\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import csv\n",
    "\n",
    "url = 'https://www.youtube.com/@PW-Foundation/videos'\n",
    "\n",
    "# Use Selenium to load the dynamic content\n",
    "driver = webdriver.Chrome()  # Make sure you have Chrome WebDriver installed and in PATH\n",
    "driver.get(url)\n",
    "time.sleep(5)  # Wait for the page to load dynamically (you can adjust this time if needed)\n",
    "\n",
    "# Now get the page source with the dynamically loaded content\n",
    "page_source = driver.page_source\n",
    "driver.quit()  # Close the browser\n",
    "\n",
    "soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "video_links = []\n",
    "\n",
    "# Find all the video link elements\n",
    "link_elements = soup.find_all('img', class_='yt-core-image--fill-parent-height yt-core-image--fill-parent-width yt-core-image yt-core-image--content-mode-scale-aspect-fill yt-core-image--loaded') \n",
    "\n",
    "\n",
    "for i, link in enumerate(link_elements):\n",
    "    if i >= 6:\n",
    "        break\n",
    "    src = link.get('src') \n",
    "    video_links.append(src)  \n",
    "\n",
    "print(video_links)\n",
    "\n",
    "# Save the video links into a CSV file\n",
    "csv_file = 'video_links.csv'\n",
    "with open(csv_file, 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Video Links'])\n",
    "    writer.writerows([[link] for link in video_links])\n",
    "\n",
    "print(f\"Video links saved to {csv_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fcaaa7f9-fd36-4dcc-9c75-221d89804cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://github.com/iPrasanjitRoy/Python-Project/raw/main/02.PNG\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "url = \"https://github.com/iPrasanjitRoy/Python-Project/raw/main/02.PNG\"  # Update the URL to the direct raw image URL\n",
    "display(Image(url=url))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7b180e-a1d4-4a64-a258-31b1bd66da40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3. Write a python program to extract the title of the first five videos.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import csv\n",
    "\n",
    "url = 'https://www.youtube.com/@PW-Foundation/videos'\n",
    "\n",
    "# Use Selenium to load the dynamic content\n",
    "driver = webdriver.Chrome()  # Make sure you have Chrome WebDriver installed and in PATH\n",
    "driver.get(url)\n",
    "time.sleep(5)  # Wait for the page to load dynamically (you can adjust this time if needed)\n",
    "\n",
    "# Now get the page source with the dynamically loaded content\n",
    "page_source = driver.page_source\n",
    "driver.quit()  # Close the browser\n",
    "\n",
    "soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "# Find all the video link elements\n",
    "link_elements = soup.find_all('a', class_='yt-simple-endpoint focus-on-expand style-scope ytd-rich-grid-media')\n",
    "\n",
    "# Extract the titles of the first five video link elements\n",
    "video_titles = []\n",
    "for i, link in enumerate(link_elements):\n",
    "    if i >= 5:\n",
    "        break\n",
    "    video_title = link.get('title')\n",
    "    video_titles.append(video_title)\n",
    "    print(f\"{i + 1}. Title: {video_title}\")\n",
    "\n",
    "# Save the video titles into a CSV file\n",
    "csv_file = 'video_titles.csv'\n",
    "with open(csv_file, 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Video Titles'])\n",
    "    writer.writerows([[title] for title in video_titles])\n",
    "\n",
    "print(f\"Video titles saved to {csv_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5a189e5c-55db-4749-93fa-e2d69bbbe074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://github.com/iPrasanjitRoy/Python-Project/raw/main/03.PNG\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "url = \"https://github.com/iPrasanjitRoy/Python-Project/raw/main/03.PNG\"  # Update the URL to the direct raw image URL\n",
    "display(Image(url=url))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d07bd7-9cc0-4ff7-992a-c4e6fc03b370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4. Write a python program to extract the number of views of the first five videos.\n",
    "\n",
    "\n",
    "\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import csv\n",
    "\n",
    "url = 'https://www.youtube.com/@PW-Foundation/videos'\n",
    "\n",
    "# Use Selenium to load the dynamic content\n",
    "driver = webdriver.Chrome()  # Make sure you have Chrome WebDriver installed and in PATH\n",
    "driver.get(url)\n",
    "time.sleep(5)  # Wait for the page to load dynamically (you can adjust this time if needed)\n",
    "\n",
    "# Now get the page source with the dynamically loaded content\n",
    "page_source = driver.page_source\n",
    "driver.quit()  # Close the browser\n",
    "\n",
    "soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "# Find all the video view count elements\n",
    "view_count_elements = soup.find_all('span', class_='inline-metadata-item style-scope ytd-video-meta-block')\n",
    "\n",
    "# Print the view counts of the first five videos at odd positions\n",
    "count = 0\n",
    "view_counts = []  # Initialize the view_counts list\n",
    "for i, view_count_element in enumerate(view_count_elements):\n",
    "    if count >= 5:\n",
    "        break\n",
    "    if (i + 1) % 2 == 1:  # Check for odd positions (odd indices)\n",
    "        count += 1\n",
    "        view_count = view_count_element.text.strip() if view_count_element else 'View count not available'\n",
    "        print(f\"{count}. View Count: {view_count}\")\n",
    "        view_counts.append(view_count)  # Add the view count to the view_counts list\n",
    "\n",
    "# Save the view counts into a CSV file\n",
    "csv_file = 'view_counts.csv'\n",
    "with open(csv_file, 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['View Count'])\n",
    "    writer.writerows([[view_count] for view_count in view_counts])\n",
    "\n",
    "print(f\"View counts saved to {csv_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aa02d839-0fd7-417f-9a8a-365b37bf623f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://github.com/iPrasanjitRoy/Python-Project/raw/main/04.PNG\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "url = \"https://github.com/iPrasanjitRoy/Python-Project/raw/main/04.PNG\"  # Update the URL to the direct raw image URL\n",
    "display(Image(url=url))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b9903d-f288-4963-af5f-9f04c981f6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5. Write a python program to extract the time of posting of video for the first five videos\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import csv\n",
    "\n",
    "url = 'https://www.youtube.com/@PW-Foundation/videos'\n",
    "\n",
    "# Use Selenium to load the dynamic content\n",
    "driver = webdriver.Chrome()  # Make sure you have Chrome WebDriver installed and in PATH\n",
    "driver.get(url)\n",
    "time.sleep(5)  # Wait for the page to load dynamically (you can adjust this time if needed)\n",
    "\n",
    "# Now get the page source with the dynamically loaded content\n",
    "page_source = driver.page_source\n",
    "driver.quit()  # Close the browser\n",
    "\n",
    "soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "# Find all the video view count elements\n",
    "view_count_elements = soup.find_all('span', class_='inline-metadata-item style-scope ytd-video-meta-block')\n",
    "\n",
    "# Store the posting dates of the first five videos at odd positions in a list\n",
    "posting_dates = []\n",
    "count = 0\n",
    "for i, view_count_element in enumerate(view_count_elements):\n",
    "    if count >= 5:\n",
    "        break\n",
    "    if (i + 1) % 2 == 0:  # Check for odd positions (odd indices)\n",
    "        count += 1\n",
    "        posting_date = view_count_element.text.strip() if view_count_element else 'Posting date not available'\n",
    "        posting_dates.append(posting_date)\n",
    "        print(f\"{count}. Posting of video: {posting_date}\")\n",
    "\n",
    "# Save the posting dates into a CSV file\n",
    "csv_file = 'posting_dates.csv'\n",
    "with open(csv_file, 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Posting Date'])\n",
    "    writer.writerows([[date] for date in posting_dates])\n",
    "\n",
    "print(f\"Posting dates saved to {csv_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ccc299fb-dd32-4a77-a030-6ce96a411c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://github.com/iPrasanjitRoy/Python-Project/raw/main/05.PNG\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "url = \"https://github.com/iPrasanjitRoy/Python-Project/raw/main/05.PNG\"  # Update the URL to the direct raw image URL\n",
    "display(Image(url=url))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca04b143-6d45-4a3d-bb00-2ddc56c604e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
